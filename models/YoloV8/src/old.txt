
# if __name__ == "__main__":
    
#     args=parse_args()
#     print("Started...")
#     detector = YOLOv8Detector(args.model_path)
#     tracker = DeepSortTracker("models/mars-small128.pb")
#     classification_model=tf.keras.saving.load_model('models\\weights.h5')
    
#     print("Models are loaded.")

#     cap = cv2.VideoCapture(args.video_path)
#     width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) 
#     fps = cap.get(cv2.CAP_PROP_FPS)
#     count = 0
    
#      # Define the codec and create a VideoWriter object
#     fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can use other codecs such as 'MJPG', 'X264', etc.
#     output_video_path = 'output_video.avi'  # Choose the desired output video file path
#     out = cv2.VideoWriter(output_video_path, fourcc, fps, (640, 640))  # Use the same fps as input video
    
#     trajectory=[]
#     trajectory_polylines=[]
    
#     person_count=0
#     group_count=0
#     tracked_people={}
#     tracked_group={}
#     while cap.isOpened():
#         start_time=time.time()
#         count += 1

#         if count % 5 == 0:
#             try:
#                 ret, frame = cap.read()
#                 if not ret:
#                     break
#                 if frame is None:
#                     raise Exception
#             except:
#                 print("Cannot read the frame.")
#                 continue
            
#             draw_frame = frame.copy()
#             draw_frame=cv2.resize(draw_frame,(640,640))
#             draw_frame_orig=draw_frame.copy()
#             dets, r = detector.detect(draw_frame)
#             cv2.line(draw_frame,(0,320),(640,320),(0,255,0),1)
#             for i in range(len(r[0])):
#                 boxes = r[0].boxes
#                 box = boxes[i].cpu()  # returns one box
#                 clsID = box.cls.numpy()[0]
#                 print(clsID)
#                 conf = box.conf.numpy()[0]
#                 bb = box.xyxy.numpy()[0]
    
                    
#                 if args.group==0:
#                     print(clsID)
#                     # if clsID==1:
                        
#                     cv2.rectangle(
#                                 draw_frame,
#                                 (int(bb[0]), int(bb[1])),
#                                 (int(bb[2]), int(bb[3])),
#                                 detection_colors[int(clsID)],
#                                 1,
#                             )
                        
#                     # if clsID==1: #if detected class is person
#                     center_x=(bb[0]+bb[2])/2
#                     center_y=(bb[1]+bb[3])/2
#                     trajectory.append((int(center_x),int(center_y)))
#                     trajectory_polylines.append([int(center_x),int(center_y)])
#                     cv2.circle(draw_frame,(int(center_x),int(center_y)),4,detection_colors[int(clsID)],-1) #draw circle to the center
                  
                
#                     class_ids=[d[-1]for d in dets]
                    
#                     if dets==[]:
#                         continue
                    
#                                 # Algılanan nesnelerin sınıflarını kontrol ederek, sınıf kimliği 0 olmayanları yeni bir liste olarak saklayın
#                     # filtered_dets = [d for d in dets if d[-1] != 0]
#                     # filtered_dets_group= [d for d in dets if d[-1] !=1]

#                     # Eğer sadece sınıf kimliği 0 olmayan nesneler varsa işlem yap
#                     # if filtered_dets:
#                     deleted_track_ids = tracker.update(draw_frame, dets)
#                     for track, class_id in zip(tracker.tracks, class_ids):
#                         if class_id == 1:  # Eğer sınıf kimliği 1 ise (yani insan ise)
#                                 p_bbox = list(map(int, track.bbox))
#                                 x1, y1, x2, y2 = p_bbox
#                                 track_id = track.track_id
#                                 center_x = int((x1 + x2) / 2)
#                                 center_y = int((y1 + y2) / 2)
#                                 draw_info(draw_frame, track_id, p_bbox, class_id)   
#                                 if track_id not in tracked_people:  # Eğer takip edilen kişi takip edilmiyorsa
#                                     if center_y >= 320:  # Eğer kişi çizgiyi geçtiyse
#                                         cropped_image=draw_frame_orig[y1:y2,x1:x2]
#                                         print(cropped_image.shape)
#                                         # resized_image=cv2.resize(cropped_image,(224,224))
                                        
#                                         result=classification(cropped_image,classification_model)
#                                         plt.imshow(cropped_image)
#                                         plt.title(result)
#                                         plt.waitforbuttonpress()
#                                         tracked_people[track_id] = True  # Takip edildi olarak işaretle
#                                         person_count += 1  # İnsan sayısını artır
                
#                     # else:
#                     #     continue
                            
#                 # if args.group==1:
#                     """
#                     Burası doldurulacak
#                     """
#                     pass
#             end_time = time.time()  # İşlem bitiş zamanını kaydet
#             elapsed_time = end_time - start_time  # Geçen süreyi hesapla
#             fps = 1 / elapsed_time  # FPS değerini hesapla
#             fps = "{:.2f}".format(fps)
#             draw_frame_text=return_frame_with_count_info(draw_frame,person_count,fps)
#             out.write(draw_frame_text)
#             cv2.imshow("Test", draw_frame_text)
        
#             if cv2.waitKey(1) == 27:
#                 break
            
            
# out.release()
# cap.release()
# cv2.destroyAllWindows()
